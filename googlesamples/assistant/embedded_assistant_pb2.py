# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: google/assistant/embedded/v1alpha1/embedded_assistant.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import descriptor_pb2
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2
from google.rpc import status_pb2 as google_dot_rpc_dot_status__pb2


DESCRIPTOR = _descriptor.FileDescriptor(
  name='google/assistant/embedded/v1alpha1/embedded_assistant.proto',
  package='google.assistant.embedded.v1alpha1',
  syntax='proto3',
  serialized_pb=_b('\n;google/assistant/embedded/v1alpha1/embedded_assistant.proto\x12\"google.assistant.embedded.v1alpha1\x1a\x1cgoogle/api/annotations.proto\x1a\x17google/rpc/status.proto\"\xe4\x01\n\x0e\x43onverseConfig\x12J\n\x0f\x61udio_in_config\x18\x01 \x01(\x0b\x32\x31.google.assistant.embedded.v1alpha1.AudioInConfig\x12L\n\x10\x61udio_out_config\x18\x02 \x01(\x0b\x32\x32.google.assistant.embedded.v1alpha1.AudioOutConfig\x12\x38\n\x05state\x18\x03 \x01(\x0b\x32).google.assistant.embedded.v1alpha1.State\"\xca\x01\n\rAudioInConfig\x12L\n\x08\x65ncoding\x18\x01 \x01(\x0e\x32:.google.assistant.embedded.v1alpha1.AudioInConfig.Encoding\x12\x19\n\x11sample_rate_hertz\x18\x02 \x01(\x05\x12\x12\n\nauth_token\x18\x64 \x01(\t\"<\n\x08\x45ncoding\x12\x18\n\x14\x45NCODING_UNSPECIFIED\x10\x00\x12\x0c\n\x08LINEAR16\x10\x01\x12\x08\n\x04\x46LAC\x10\x02\"\xe3\x01\n\x0e\x41udioOutConfig\x12M\n\x08\x65ncoding\x18\x01 \x01(\x0e\x32;.google.assistant.embedded.v1alpha1.AudioOutConfig.Encoding\x12\x19\n\x11sample_rate_hertz\x18\x02 \x01(\x05\x12\x19\n\x11volume_percentage\x18\x03 \x01(\x05\"L\n\x08\x45ncoding\x12\x18\n\x14\x45NCODING_UNSPECIFIED\x10\x00\x12\x0c\n\x08LINEAR16\x10\x01\x12\x07\n\x03MP3\x10\x02\x12\x0f\n\x0bOPUS_IN_OGG\x10\x03\"#\n\x05State\x12\x1a\n\x0e\x63onverse_state\x18\x01 \x01(\tB\x02\x08\x01\"X\n\x08\x41udioOut\x12\x16\n\naudio_data\x18\x01 \x01(\x0c\x42\x02\x08\x01\x12\x19\n\x11sample_rate_hertz\x18\x02 \x01(\x05\x12\x19\n\x11volume_percentage\x18\x03 \x01(\x05\"\x92\x02\n\x06Result\x12\x1b\n\x13spoken_request_text\x18\x01 \x01(\t\x12\x1c\n\x14spoken_response_text\x18\x02 \x01(\t\x12\x1a\n\x0e\x63onverse_state\x18\x03 \x01(\tB\x02\x08\x01\x12R\n\x0fmicrophone_mode\x18\x04 \x01(\x0e\x32\x39.google.assistant.embedded.v1alpha1.Result.MicrophoneMode\"]\n\x0eMicrophoneMode\x12\x1f\n\x1bMICROPHONE_MODE_UNSPECIFIED\x10\x00\x12\x14\n\x10\x43LOSE_MICROPHONE\x10\x01\x12\x14\n\x10\x44IALOG_FOLLOW_ON\x10\x02\"\x83\x01\n\x0f\x43onverseRequest\x12\x44\n\x06\x63onfig\x18\x01 \x01(\x0b\x32\x32.google.assistant.embedded.v1alpha1.ConverseConfigH\x00\x12\x16\n\x08\x61udio_in\x18\x02 \x01(\x0c\x42\x02\x08\x01H\x00\x42\x12\n\x10\x63onverse_request\"\xe2\x02\n\x10\x43onverseResponse\x12#\n\x05\x65rror\x18\x01 \x01(\x0b\x32\x12.google.rpc.StatusH\x00\x12T\n\nevent_type\x18\x02 \x01(\x0e\x32>.google.assistant.embedded.v1alpha1.ConverseResponse.EventTypeH\x00\x12\x41\n\taudio_out\x18\x03 \x01(\x0b\x32,.google.assistant.embedded.v1alpha1.AudioOutH\x00\x12<\n\x06result\x18\x05 \x01(\x0b\x32*.google.assistant.embedded.v1alpha1.ResultH\x00\"=\n\tEventType\x12\x1a\n\x16\x45VENT_TYPE_UNSPECIFIED\x10\x00\x12\x14\n\x10\x45ND_OF_UTTERANCE\x10\x01\x42\x13\n\x11\x63onverse_response2\x8e\x01\n\x11\x45mbeddedAssistant\x12y\n\x08\x43onverse\x12\x33.google.assistant.embedded.v1alpha1.ConverseRequest\x1a\x34.google.assistant.embedded.v1alpha1.ConverseResponse(\x01\x30\x01\x42:\n&com.google.assistant.embedded.v1alpha1B\x0e\x41ssistantProtoP\x01\x62\x06proto3')
  ,
  dependencies=[google_dot_api_dot_annotations__pb2.DESCRIPTOR,google_dot_rpc_dot_status__pb2.DESCRIPTOR,])
_sym_db.RegisterFileDescriptor(DESCRIPTOR)



_AUDIOINCONFIG_ENCODING = _descriptor.EnumDescriptor(
  name='Encoding',
  full_name='google.assistant.embedded.v1alpha1.AudioInConfig.Encoding',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='ENCODING_UNSPECIFIED', index=0, number=0,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='LINEAR16', index=1, number=1,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='FLAC', index=2, number=2,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=528,
  serialized_end=588,
)
_sym_db.RegisterEnumDescriptor(_AUDIOINCONFIG_ENCODING)

_AUDIOOUTCONFIG_ENCODING = _descriptor.EnumDescriptor(
  name='Encoding',
  full_name='google.assistant.embedded.v1alpha1.AudioOutConfig.Encoding',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='ENCODING_UNSPECIFIED', index=0, number=0,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='LINEAR16', index=1, number=1,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='MP3', index=2, number=2,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='OPUS_IN_OGG', index=3, number=3,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=742,
  serialized_end=818,
)
_sym_db.RegisterEnumDescriptor(_AUDIOOUTCONFIG_ENCODING)

_RESULT_MICROPHONEMODE = _descriptor.EnumDescriptor(
  name='MicrophoneMode',
  full_name='google.assistant.embedded.v1alpha1.Result.MicrophoneMode',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='MICROPHONE_MODE_UNSPECIFIED', index=0, number=0,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='CLOSE_MICROPHONE', index=1, number=1,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='DIALOG_FOLLOW_ON', index=2, number=2,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=1129,
  serialized_end=1222,
)
_sym_db.RegisterEnumDescriptor(_RESULT_MICROPHONEMODE)

_CONVERSERESPONSE_EVENTTYPE = _descriptor.EnumDescriptor(
  name='EventType',
  full_name='google.assistant.embedded.v1alpha1.ConverseResponse.EventType',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='EVENT_TYPE_UNSPECIFIED', index=0, number=0,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='END_OF_UTTERANCE', index=1, number=1,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=1631,
  serialized_end=1692,
)
_sym_db.RegisterEnumDescriptor(_CONVERSERESPONSE_EVENTTYPE)


_CONVERSECONFIG = _descriptor.Descriptor(
  name='ConverseConfig',
  full_name='google.assistant.embedded.v1alpha1.ConverseConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='audio_in_config', full_name='google.assistant.embedded.v1alpha1.ConverseConfig.audio_in_config', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='audio_out_config', full_name='google.assistant.embedded.v1alpha1.ConverseConfig.audio_out_config', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='state', full_name='google.assistant.embedded.v1alpha1.ConverseConfig.state', index=2,
      number=3, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=155,
  serialized_end=383,
)


_AUDIOINCONFIG = _descriptor.Descriptor(
  name='AudioInConfig',
  full_name='google.assistant.embedded.v1alpha1.AudioInConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='encoding', full_name='google.assistant.embedded.v1alpha1.AudioInConfig.encoding', index=0,
      number=1, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='sample_rate_hertz', full_name='google.assistant.embedded.v1alpha1.AudioInConfig.sample_rate_hertz', index=1,
      number=2, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='auth_token', full_name='google.assistant.embedded.v1alpha1.AudioInConfig.auth_token', index=2,
      number=100, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _AUDIOINCONFIG_ENCODING,
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=386,
  serialized_end=588,
)


_AUDIOOUTCONFIG = _descriptor.Descriptor(
  name='AudioOutConfig',
  full_name='google.assistant.embedded.v1alpha1.AudioOutConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='encoding', full_name='google.assistant.embedded.v1alpha1.AudioOutConfig.encoding', index=0,
      number=1, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='sample_rate_hertz', full_name='google.assistant.embedded.v1alpha1.AudioOutConfig.sample_rate_hertz', index=1,
      number=2, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='volume_percentage', full_name='google.assistant.embedded.v1alpha1.AudioOutConfig.volume_percentage', index=2,
      number=3, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _AUDIOOUTCONFIG_ENCODING,
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=591,
  serialized_end=818,
)


_STATE = _descriptor.Descriptor(
  name='State',
  full_name='google.assistant.embedded.v1alpha1.State',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='converse_state', full_name='google.assistant.embedded.v1alpha1.State.converse_state', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\010\001'))),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=820,
  serialized_end=855,
)


_AUDIOOUT = _descriptor.Descriptor(
  name='AudioOut',
  full_name='google.assistant.embedded.v1alpha1.AudioOut',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='audio_data', full_name='google.assistant.embedded.v1alpha1.AudioOut.audio_data', index=0,
      number=1, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\010\001'))),
    _descriptor.FieldDescriptor(
      name='sample_rate_hertz', full_name='google.assistant.embedded.v1alpha1.AudioOut.sample_rate_hertz', index=1,
      number=2, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='volume_percentage', full_name='google.assistant.embedded.v1alpha1.AudioOut.volume_percentage', index=2,
      number=3, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=857,
  serialized_end=945,
)


_RESULT = _descriptor.Descriptor(
  name='Result',
  full_name='google.assistant.embedded.v1alpha1.Result',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='spoken_request_text', full_name='google.assistant.embedded.v1alpha1.Result.spoken_request_text', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='spoken_response_text', full_name='google.assistant.embedded.v1alpha1.Result.spoken_response_text', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='converse_state', full_name='google.assistant.embedded.v1alpha1.Result.converse_state', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\010\001'))),
    _descriptor.FieldDescriptor(
      name='microphone_mode', full_name='google.assistant.embedded.v1alpha1.Result.microphone_mode', index=3,
      number=4, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _RESULT_MICROPHONEMODE,
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=948,
  serialized_end=1222,
)


_CONVERSEREQUEST = _descriptor.Descriptor(
  name='ConverseRequest',
  full_name='google.assistant.embedded.v1alpha1.ConverseRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='config', full_name='google.assistant.embedded.v1alpha1.ConverseRequest.config', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='audio_in', full_name='google.assistant.embedded.v1alpha1.ConverseRequest.audio_in', index=1,
      number=2, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\010\001'))),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='converse_request', full_name='google.assistant.embedded.v1alpha1.ConverseRequest.converse_request',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=1225,
  serialized_end=1356,
)


_CONVERSERESPONSE = _descriptor.Descriptor(
  name='ConverseResponse',
  full_name='google.assistant.embedded.v1alpha1.ConverseResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='error', full_name='google.assistant.embedded.v1alpha1.ConverseResponse.error', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='event_type', full_name='google.assistant.embedded.v1alpha1.ConverseResponse.event_type', index=1,
      number=2, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='audio_out', full_name='google.assistant.embedded.v1alpha1.ConverseResponse.audio_out', index=2,
      number=3, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='result', full_name='google.assistant.embedded.v1alpha1.ConverseResponse.result', index=3,
      number=5, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _CONVERSERESPONSE_EVENTTYPE,
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='converse_response', full_name='google.assistant.embedded.v1alpha1.ConverseResponse.converse_response',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=1359,
  serialized_end=1713,
)

_CONVERSECONFIG.fields_by_name['audio_in_config'].message_type = _AUDIOINCONFIG
_CONVERSECONFIG.fields_by_name['audio_out_config'].message_type = _AUDIOOUTCONFIG
_CONVERSECONFIG.fields_by_name['state'].message_type = _STATE
_AUDIOINCONFIG.fields_by_name['encoding'].enum_type = _AUDIOINCONFIG_ENCODING
_AUDIOINCONFIG_ENCODING.containing_type = _AUDIOINCONFIG
_AUDIOOUTCONFIG.fields_by_name['encoding'].enum_type = _AUDIOOUTCONFIG_ENCODING
_AUDIOOUTCONFIG_ENCODING.containing_type = _AUDIOOUTCONFIG
_RESULT.fields_by_name['microphone_mode'].enum_type = _RESULT_MICROPHONEMODE
_RESULT_MICROPHONEMODE.containing_type = _RESULT
_CONVERSEREQUEST.fields_by_name['config'].message_type = _CONVERSECONFIG
_CONVERSEREQUEST.oneofs_by_name['converse_request'].fields.append(
  _CONVERSEREQUEST.fields_by_name['config'])
_CONVERSEREQUEST.fields_by_name['config'].containing_oneof = _CONVERSEREQUEST.oneofs_by_name['converse_request']
_CONVERSEREQUEST.oneofs_by_name['converse_request'].fields.append(
  _CONVERSEREQUEST.fields_by_name['audio_in'])
_CONVERSEREQUEST.fields_by_name['audio_in'].containing_oneof = _CONVERSEREQUEST.oneofs_by_name['converse_request']
_CONVERSERESPONSE.fields_by_name['error'].message_type = google_dot_rpc_dot_status__pb2._STATUS
_CONVERSERESPONSE.fields_by_name['event_type'].enum_type = _CONVERSERESPONSE_EVENTTYPE
_CONVERSERESPONSE.fields_by_name['audio_out'].message_type = _AUDIOOUT
_CONVERSERESPONSE.fields_by_name['result'].message_type = _RESULT
_CONVERSERESPONSE_EVENTTYPE.containing_type = _CONVERSERESPONSE
_CONVERSERESPONSE.oneofs_by_name['converse_response'].fields.append(
  _CONVERSERESPONSE.fields_by_name['error'])
_CONVERSERESPONSE.fields_by_name['error'].containing_oneof = _CONVERSERESPONSE.oneofs_by_name['converse_response']
_CONVERSERESPONSE.oneofs_by_name['converse_response'].fields.append(
  _CONVERSERESPONSE.fields_by_name['event_type'])
_CONVERSERESPONSE.fields_by_name['event_type'].containing_oneof = _CONVERSERESPONSE.oneofs_by_name['converse_response']
_CONVERSERESPONSE.oneofs_by_name['converse_response'].fields.append(
  _CONVERSERESPONSE.fields_by_name['audio_out'])
_CONVERSERESPONSE.fields_by_name['audio_out'].containing_oneof = _CONVERSERESPONSE.oneofs_by_name['converse_response']
_CONVERSERESPONSE.oneofs_by_name['converse_response'].fields.append(
  _CONVERSERESPONSE.fields_by_name['result'])
_CONVERSERESPONSE.fields_by_name['result'].containing_oneof = _CONVERSERESPONSE.oneofs_by_name['converse_response']
DESCRIPTOR.message_types_by_name['ConverseConfig'] = _CONVERSECONFIG
DESCRIPTOR.message_types_by_name['AudioInConfig'] = _AUDIOINCONFIG
DESCRIPTOR.message_types_by_name['AudioOutConfig'] = _AUDIOOUTCONFIG
DESCRIPTOR.message_types_by_name['State'] = _STATE
DESCRIPTOR.message_types_by_name['AudioOut'] = _AUDIOOUT
DESCRIPTOR.message_types_by_name['Result'] = _RESULT
DESCRIPTOR.message_types_by_name['ConverseRequest'] = _CONVERSEREQUEST
DESCRIPTOR.message_types_by_name['ConverseResponse'] = _CONVERSERESPONSE

ConverseConfig = _reflection.GeneratedProtocolMessageType('ConverseConfig', (_message.Message,), dict(
  DESCRIPTOR = _CONVERSECONFIG,
  __module__ = 'google.assistant.embedded.v1alpha1.embedded_assistant_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.ConverseConfig)
  ))
_sym_db.RegisterMessage(ConverseConfig)

AudioInConfig = _reflection.GeneratedProtocolMessageType('AudioInConfig', (_message.Message,), dict(
  DESCRIPTOR = _AUDIOINCONFIG,
  __module__ = 'google.assistant.embedded.v1alpha1.embedded_assistant_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.AudioInConfig)
  ))
_sym_db.RegisterMessage(AudioInConfig)

AudioOutConfig = _reflection.GeneratedProtocolMessageType('AudioOutConfig', (_message.Message,), dict(
  DESCRIPTOR = _AUDIOOUTCONFIG,
  __module__ = 'google.assistant.embedded.v1alpha1.embedded_assistant_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.AudioOutConfig)
  ))
_sym_db.RegisterMessage(AudioOutConfig)

State = _reflection.GeneratedProtocolMessageType('State', (_message.Message,), dict(
  DESCRIPTOR = _STATE,
  __module__ = 'google.assistant.embedded.v1alpha1.embedded_assistant_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.State)
  ))
_sym_db.RegisterMessage(State)

AudioOut = _reflection.GeneratedProtocolMessageType('AudioOut', (_message.Message,), dict(
  DESCRIPTOR = _AUDIOOUT,
  __module__ = 'google.assistant.embedded.v1alpha1.embedded_assistant_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.AudioOut)
  ))
_sym_db.RegisterMessage(AudioOut)

Result = _reflection.GeneratedProtocolMessageType('Result', (_message.Message,), dict(
  DESCRIPTOR = _RESULT,
  __module__ = 'google.assistant.embedded.v1alpha1.embedded_assistant_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.Result)
  ))
_sym_db.RegisterMessage(Result)

ConverseRequest = _reflection.GeneratedProtocolMessageType('ConverseRequest', (_message.Message,), dict(
  DESCRIPTOR = _CONVERSEREQUEST,
  __module__ = 'google.assistant.embedded.v1alpha1.embedded_assistant_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.ConverseRequest)
  ))
_sym_db.RegisterMessage(ConverseRequest)

ConverseResponse = _reflection.GeneratedProtocolMessageType('ConverseResponse', (_message.Message,), dict(
  DESCRIPTOR = _CONVERSERESPONSE,
  __module__ = 'google.assistant.embedded.v1alpha1.embedded_assistant_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.ConverseResponse)
  ))
_sym_db.RegisterMessage(ConverseResponse)


DESCRIPTOR.has_options = True
DESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b('\n&com.google.assistant.embedded.v1alpha1B\016AssistantProtoP\001'))
_STATE.fields_by_name['converse_state'].has_options = True
_STATE.fields_by_name['converse_state']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\010\001'))
_AUDIOOUT.fields_by_name['audio_data'].has_options = True
_AUDIOOUT.fields_by_name['audio_data']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\010\001'))
_RESULT.fields_by_name['converse_state'].has_options = True
_RESULT.fields_by_name['converse_state']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\010\001'))
_CONVERSEREQUEST.fields_by_name['audio_in'].has_options = True
_CONVERSEREQUEST.fields_by_name['audio_in']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\010\001'))
try:
  # THESE ELEMENTS WILL BE DEPRECATED.
  # Please use the generated *_pb2_grpc.py files instead.
  import grpc
  from grpc.framework.common import cardinality
  from grpc.framework.interfaces.face import utilities as face_utilities
  from grpc.beta import implementations as beta_implementations
  from grpc.beta import interfaces as beta_interfaces


  class EmbeddedAssistantStub(object):
    """Service that implements Embedded Google Assistant API.
    """

    def __init__(self, channel):
      """Constructor.

      Args:
        channel: A grpc.Channel.
      """
      self.Converse = channel.stream_stream(
          '/google.assistant.embedded.v1alpha1.EmbeddedAssistant/Converse',
          request_serializer=ConverseRequest.SerializeToString,
          response_deserializer=ConverseResponse.FromString,
          )


  class EmbeddedAssistantServicer(object):
    """Service that implements Embedded Google Assistant API.
    """

    def Converse(self, request_iterator, context):
      """Initiates or continues a conversation with the embedded assistant service.
      Each call performs one round-trip, sending an audio request to the service
      and receiving the audio response. Uses bidirectional streaming to receive
      results, such as the `END_OF_UTTERANCE` event, while sending audio.

      A conversation is one or more gRPC connections, each consisting of several
      streamed requests and responses. For example, if the user said "Set timer"
      and the assistant responds "For how long?", the sequence could be:

      ConverseRequest.config
      ConverseRequest.audio_in
      ConverseRequest.audio_in
      ConverseRequest.audio_in
      ConverseResponse.event_type.END_OF_UTTERANCE
      ConverseResponse.result
      ConverseResponse.audio_out
      ConverseResponse.audio_out
      ConverseResponse.audio_out

      Then the user says "Two minutes" and the assistant responds
      "Two minute timer, starting now". This is sent as another gRPC connection
      call to the `Converse` method, again with streamed requests and responses,
      such as:

      ConverseRequest.config
      ConverseRequest.audio_in
      ConverseRequest.audio_in
      ConverseRequest.audio_in
      ConverseResponse.event_type.END_OF_UTTERANCE
      ConverseResponse.result
      ConverseResponse.audio_out
      ConverseResponse.audio_out
      ConverseResponse.audio_out
      """
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')


  def add_EmbeddedAssistantServicer_to_server(servicer, server):
    rpc_method_handlers = {
        'Converse': grpc.stream_stream_rpc_method_handler(
            servicer.Converse,
            request_deserializer=ConverseRequest.FromString,
            response_serializer=ConverseResponse.SerializeToString,
        ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
        'google.assistant.embedded.v1alpha1.EmbeddedAssistant', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


  class BetaEmbeddedAssistantServicer(object):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0."""
    """Service that implements Embedded Google Assistant API.
    """
    def Converse(self, request_iterator, context):
      """Initiates or continues a conversation with the embedded assistant service.
      Each call performs one round-trip, sending an audio request to the service
      and receiving the audio response. Uses bidirectional streaming to receive
      results, such as the `END_OF_UTTERANCE` event, while sending audio.

      A conversation is one or more gRPC connections, each consisting of several
      streamed requests and responses. For example, if the user said "Set timer"
      and the assistant responds "For how long?", the sequence could be:

      ConverseRequest.config
      ConverseRequest.audio_in
      ConverseRequest.audio_in
      ConverseRequest.audio_in
      ConverseResponse.event_type.END_OF_UTTERANCE
      ConverseResponse.result
      ConverseResponse.audio_out
      ConverseResponse.audio_out
      ConverseResponse.audio_out

      Then the user says "Two minutes" and the assistant responds
      "Two minute timer, starting now". This is sent as another gRPC connection
      call to the `Converse` method, again with streamed requests and responses,
      such as:

      ConverseRequest.config
      ConverseRequest.audio_in
      ConverseRequest.audio_in
      ConverseRequest.audio_in
      ConverseResponse.event_type.END_OF_UTTERANCE
      ConverseResponse.result
      ConverseResponse.audio_out
      ConverseResponse.audio_out
      ConverseResponse.audio_out
      """
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)


  class BetaEmbeddedAssistantStub(object):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0."""
    """Service that implements Embedded Google Assistant API.
    """
    def Converse(self, request_iterator, timeout, metadata=None, with_call=False, protocol_options=None):
      """Initiates or continues a conversation with the embedded assistant service.
      Each call performs one round-trip, sending an audio request to the service
      and receiving the audio response. Uses bidirectional streaming to receive
      results, such as the `END_OF_UTTERANCE` event, while sending audio.

      A conversation is one or more gRPC connections, each consisting of several
      streamed requests and responses. For example, if the user said "Set timer"
      and the assistant responds "For how long?", the sequence could be:

      ConverseRequest.config
      ConverseRequest.audio_in
      ConverseRequest.audio_in
      ConverseRequest.audio_in
      ConverseResponse.event_type.END_OF_UTTERANCE
      ConverseResponse.result
      ConverseResponse.audio_out
      ConverseResponse.audio_out
      ConverseResponse.audio_out

      Then the user says "Two minutes" and the assistant responds
      "Two minute timer, starting now". This is sent as another gRPC connection
      call to the `Converse` method, again with streamed requests and responses,
      such as:

      ConverseRequest.config
      ConverseRequest.audio_in
      ConverseRequest.audio_in
      ConverseRequest.audio_in
      ConverseResponse.event_type.END_OF_UTTERANCE
      ConverseResponse.result
      ConverseResponse.audio_out
      ConverseResponse.audio_out
      ConverseResponse.audio_out
      """
      raise NotImplementedError()


  def beta_create_EmbeddedAssistant_server(servicer, pool=None, pool_size=None, default_timeout=None, maximum_timeout=None):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This function was
    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0"""
    request_deserializers = {
      ('google.assistant.embedded.v1alpha1.EmbeddedAssistant', 'Converse'): ConverseRequest.FromString,
    }
    response_serializers = {
      ('google.assistant.embedded.v1alpha1.EmbeddedAssistant', 'Converse'): ConverseResponse.SerializeToString,
    }
    method_implementations = {
      ('google.assistant.embedded.v1alpha1.EmbeddedAssistant', 'Converse'): face_utilities.stream_stream_inline(servicer.Converse),
    }
    server_options = beta_implementations.server_options(request_deserializers=request_deserializers, response_serializers=response_serializers, thread_pool=pool, thread_pool_size=pool_size, default_timeout=default_timeout, maximum_timeout=maximum_timeout)
    return beta_implementations.server(method_implementations, options=server_options)


  def beta_create_EmbeddedAssistant_stub(channel, host=None, metadata_transformer=None, pool=None, pool_size=None):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This function was
    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0"""
    request_serializers = {
      ('google.assistant.embedded.v1alpha1.EmbeddedAssistant', 'Converse'): ConverseRequest.SerializeToString,
    }
    response_deserializers = {
      ('google.assistant.embedded.v1alpha1.EmbeddedAssistant', 'Converse'): ConverseResponse.FromString,
    }
    cardinalities = {
      'Converse': cardinality.Cardinality.STREAM_STREAM,
    }
    stub_options = beta_implementations.stub_options(host=host, metadata_transformer=metadata_transformer, request_serializers=request_serializers, response_deserializers=response_deserializers, thread_pool=pool, thread_pool_size=pool_size)
    return beta_implementations.dynamic_stub(channel, 'google.assistant.embedded.v1alpha1.EmbeddedAssistant', cardinalities, options=stub_options)
except ImportError:
  pass
# @@protoc_insertion_point(module_scope)
